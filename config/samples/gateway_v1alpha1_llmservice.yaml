apiVersion: gateway.inference.k8s.io/v1alpha1
kind: LLMService
metadata:
  labels:
    app.kubernetes.io/name: api
    app.kubernetes.io/managed-by: kustomize
  name: llmservice-sample
spec:
  LLMServices:
  - modelName: sql-code-assist
  - modelName: npc-bot
    objective: 
      desiredAveragePerOutputTokenLatencyAtP95OverMultipleRequests: 50ms
    targetModels:
      targetModelName: npc-bot-v1
        weight: 50
      targetModelName: npc-bot-v2
        weight: 50 	
  poolRefs:
  - name: llama-2-pool
  - name: gemini-pool
